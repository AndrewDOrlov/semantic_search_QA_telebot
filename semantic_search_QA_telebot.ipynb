{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "  # Выбор носителя\n",
        "  device = 'cuda'\n",
        "\n",
        "  # Установка библиотек\n",
        "  ! pip install pytelegrambotapi\n",
        "  ! pip install -U transformers\n",
        "  ! pip install -U accelerate\n",
        "  ! pip install sentence_transformers\n",
        "  ! pip install python-dotenv\n",
        "\n",
        "  # Загрузка бибилиотек\n",
        "  import telebot\n",
        "  from telebot import types\n",
        "  from sentence_transformers.util import semantic_search\n",
        "  import torch\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering\n",
        "  import re\n",
        "  import random\n",
        "\n",
        "  # Подключение к Google Drive (для работы в Google Colab)\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "  # Загрузка токена доступа к телеграм-боту\n",
        "  from dotenv import load_dotenv\n",
        "  import os\n",
        "  load_dotenv('drive/MyDrive/Colab Notebooks/semantic_search_QA_telebot/.env')\n",
        "  TOKEN = os.getenv(\"TOKEN\")\n",
        "\n",
        "\n",
        "  # Функции для работы с семантической моделью:\n",
        "  def get_semantic_model(device):\n",
        "    \"\"\"\n",
        "    Функция загружает модель для семантического поиска\n",
        "    \"\"\"\n",
        "    sem_model = AutoModel.from_pretrained(\n",
        "      'sentence-transformers/LaBSE').to(device)\n",
        "    return sem_model\n",
        "\n",
        "\n",
        "  def get_semantic_tokenizer():\n",
        "    \"\"\"\n",
        "    Функция загружает токенизатор модели для семантического поиска\n",
        "    \"\"\"\n",
        "    sem_tokenizer = AutoTokenizer.from_pretrained(\n",
        "      'sentence-transformers/LaBSE')\n",
        "    return sem_tokenizer\n",
        "\n",
        "\n",
        "  def get_qa_model(device):\n",
        "    \"\"\"\n",
        "    Функция загружает модель для поиска ответа на вопрос\n",
        "    \"\"\"\n",
        "    qa_model = AutoModelForQuestionAnswering.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\").to(device)\n",
        "    return qa_model\n",
        "\n",
        "\n",
        "  def get_qa_tokenizer():\n",
        "    \"\"\"\n",
        "    Функция загружает токенизатор модели для поиска ответа на вопрос\n",
        "    \"\"\"\n",
        "    qa_tokenizer = AutoTokenizer.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")\n",
        "    return qa_tokenizer\n",
        "\n",
        "\n",
        "  def mean_pooling(model_output, attention_mask):\n",
        "    \"\"\"\n",
        "    Функция выполняет объединение средних значений (mean pooling) - выбирает среднее значение среди эмбеддингов\n",
        "    \"\"\"\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "  def get_text_embeddings():\n",
        "    \"\"\"\n",
        "    Функция загружает датасет с эмбеддингами всех текстов базы знаний\n",
        "    \"\"\"\n",
        "    sentence_embeddings_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/semantic_search_QA_telebot/data/knowledge_db_128.csv\", low_memory=False, encoding = \"UTF-8\", sep = \",\")\n",
        "    sentence_embeddings_df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "    sentence_embeddings = torch.cuda.FloatTensor(sentence_embeddings_df.values)\n",
        "    return sentence_embeddings\n",
        "\n",
        "\n",
        "  def get_texts():\n",
        "    \"\"\"\n",
        "    Функция загружает датасет всех текстов базы знаний\n",
        "    \"\"\"\n",
        "    sentence_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/semantic_search_QA_telebot/data/Knowledge_base_df.csv\", low_memory=False, encoding = \"UTF-8\", sep = \",\")\n",
        "    sentences = [i for i in sentence_df[\"text\"]]\n",
        "    return sentences\n",
        "\n",
        "\n",
        "  def encode_question(tokenizer, question, model, device):\n",
        "    \"\"\"\n",
        "    Функция получает эмбеддинги вопросов пользователя к базе данных\n",
        "    \"\"\"\n",
        "    encoded_input = tokenizer(\n",
        "      question,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      max_length=128,\n",
        "      return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model_output = model(**encoded_input.to(device))\n",
        "\n",
        "    question_embeddings = mean_pooling(\n",
        "      model_output,\n",
        "      encoded_input['attention_mask']\n",
        "    )\n",
        "    return question_embeddings\n",
        "\n",
        "\n",
        "  def search(question_embeddings, sentence_embeddings):\n",
        "    \"\"\"\n",
        "    Функция выполняет семантический поиск по базе знаний\n",
        "    Выбираются k текстов из базы, наиболее близких по косинусному сходству эмбеддингов к вопросу пользователя\n",
        "    \"\"\"\n",
        "    hits = semantic_search(question_embeddings, sentence_embeddings, top_k=1)\n",
        "    return sentences[hits[0][0][\"corpus_id\"]]\n",
        "\n",
        "\n",
        "  def get_answer(qa_model, qa_tokenizer, question, text, device):\n",
        "    \"\"\"\n",
        "    Функция выполняет поиск ответа на вопрос пользователя в наиболее подходящем тексте из базы знаний\n",
        "    \"\"\"\n",
        "    # Токенизация вопроса\n",
        "    tokenized = qa_tokenizer.encode_plus(\n",
        "      question, text,\n",
        "      add_special_tokens=False\n",
        "    )\n",
        "    tokens = qa_tokenizer.convert_ids_to_tokens(tokenized['input_ids'])\n",
        "\n",
        "    # Общая длина каждого блока\n",
        "    max_chunk_length = 512\n",
        "    # Длина наложения\n",
        "    overlapped_length = 30\n",
        "    # Длина вопроса в токенах\n",
        "    answer_tokens_length = tokenized.token_type_ids.count(0)\n",
        "    # Токены вопроса, закодированные числами\n",
        "    answer_input_ids = tokenized.input_ids[:answer_tokens_length]\n",
        "    # Длина основного текста первого блока без наложения\n",
        "    first_context_chunk_length = max_chunk_length - answer_tokens_length\n",
        "    # Длина основного текста остальных блоков с наложением\n",
        "    context_chunk_length = max_chunk_length - answer_tokens_length - overlapped_length\n",
        "\n",
        "    # Токены основного текста\n",
        "    context_input_ids = tokenized.input_ids[answer_tokens_length:]\n",
        "    # Основной текст первого блока\n",
        "    first = context_input_ids[:first_context_chunk_length]\n",
        "    # Основной текст остальных блоков\n",
        "    others = context_input_ids[first_context_chunk_length:]\n",
        "\n",
        "    # Если есть блоки кроме первого\n",
        "    # тогда обрабатываются все блоки\n",
        "    if len(others) > 0:\n",
        "      # Кол-во нулевых токенов, для выравнивания последнего блока по длине\n",
        "      padding_length = context_chunk_length - (len(others) % context_chunk_length)\n",
        "      others += [0] * padding_length\n",
        "\n",
        "      # Кол-во блоков и их длина без добавления наложения\n",
        "      new_size = (\n",
        "          len(others) // context_chunk_length,\n",
        "          context_chunk_length\n",
        "      )\n",
        "\n",
        "      # Упаковка блоков\n",
        "      new_context_input_ids = np.reshape(others, new_size)\n",
        "\n",
        "      # Вычисление наложения\n",
        "      overlappeds = new_context_input_ids[:, -overlapped_length:]\n",
        "      # Добавление в наложения частей из первого блока\n",
        "      overlappeds = np.insert(overlappeds, 0, first[-overlapped_length:], axis=0)\n",
        "      # Удаление наложение из последнего блока, так как оно не нужно\n",
        "      overlappeds = overlappeds[:-1]\n",
        "\n",
        "      # Добавление наложения\n",
        "      new_context_input_ids = np.c_[overlappeds, new_context_input_ids]\n",
        "      # Добавление первого блока\n",
        "      new_context_input_ids = np.insert(new_context_input_ids, 0, first, axis=0)\n",
        "\n",
        "      # Добавление вопроса в каждый блок\n",
        "      new_input_ids = np.c_[\n",
        "        [answer_input_ids] * new_context_input_ids.shape[0],\n",
        "        new_context_input_ids\n",
        "      ]\n",
        "    # иначе обрабатывается только первый\n",
        "    else:\n",
        "      # Кол-во нулевых токенов, для выравнивания блока по длине\n",
        "      padding_length = first_context_chunk_length - (len(first) % first_context_chunk_length)\n",
        "      # Добавление нулевых токенов\n",
        "      new_input_ids = np.array(\n",
        "        [answer_input_ids + first + [0] * padding_length]\n",
        "      )\n",
        "\n",
        "    # Кол-во блоков\n",
        "    count_chunks = new_input_ids.shape[0]\n",
        "\n",
        "    # Маска, разделяющая вопрос и текст\n",
        "    new_token_type_ids = [\n",
        "      # вопрос блока\n",
        "      [0] * answer_tokens_length\n",
        "      # текст блока\n",
        "      + [1] * (max_chunk_length - answer_tokens_length)\n",
        "    ] * count_chunks\n",
        "\n",
        "    # Маска \"внимания\" модели на все токены, кроме нулевых в последнем блоке\n",
        "    new_attention_mask = (\n",
        "      # во всех блоках, кроме последнего, \"внимание\" на все слова\n",
        "      [[1] * max_chunk_length] * (count_chunks - 1)\n",
        "      # в последнем блоке \"внимание\" только на ненулевые токены\n",
        "      + [([1] * (max_chunk_length - padding_length)) + ([0] * padding_length)]\n",
        "    )\n",
        "\n",
        "    # Токенизированный текст в виде блоков, упакованный в torch\n",
        "    new_tokenized = {\n",
        "    'input_ids': torch.tensor(new_input_ids).to(device),\n",
        "    'token_type_ids': torch.tensor(new_token_type_ids).to(device),\n",
        "    'attention_mask': torch.tensor(new_attention_mask).to(device)\n",
        "    }\n",
        "    device = \"cuda\"\n",
        "    outputs = qa_model(**new_tokenized)\n",
        "\n",
        "    # Позиции в 2D списке токенов начала и конца наиболее вероятного ответа\n",
        "    # позиции одним числом\n",
        "    start_index = torch.argmax(outputs.start_logits)\n",
        "    end_index = torch.argmax(outputs.end_logits)\n",
        "\n",
        "    # Пересчёт позиций начала и конца ответа для 1D списка токенов\n",
        "    # = длина первого блока + (\n",
        "    #   позиция - длина первого блока\n",
        "    #   - длина ответов и отступов во всех блоках, кроме первого\n",
        "    # )\n",
        "    start_index = max_chunk_length + (\n",
        "      start_index - max_chunk_length\n",
        "      - (answer_tokens_length + overlapped_length)\n",
        "      * (start_index // max_chunk_length)\n",
        "    )\n",
        "    end_index = max_chunk_length + (\n",
        "      end_index - max_chunk_length\n",
        "      - (answer_tokens_length + overlapped_length)\n",
        "      * (end_index // max_chunk_length)\n",
        "    )\n",
        "\n",
        "    # Составление ответа\n",
        "    # если есть символ начала слова '▁', то он заменяется на пробел\n",
        "    answer_raw = ''.join(\n",
        "      [t.replace('▁', ' ') for t in tokens[start_index:end_index+1]]\n",
        "    )\n",
        "    # Если ответ содержит скобки, скобки удаляются\n",
        "    answer = re.sub(r\"\\(+|\\)+\", \"\", answer_raw)\n",
        "    # Возвращается словарь, содержащий ответ на вопрос (answer) и наиболее подходящий текст, откуда взят ответ (text)\n",
        "    return {\"answer\" : answer.strip(), \"text\" : text}\n",
        "\n",
        "\n",
        "  def process_question(question, sem_tokenizer, sem_model, device):\n",
        "    \"\"\"\n",
        "    Функция получает вопрос пользователя к базе данных,\n",
        "    вызывает функции:\n",
        "      получения эмбеддингов вопроса (encode_question),\n",
        "      семантического поиска подходящего текста(search),\n",
        "      поиска ответа на вопрос в тексте(get_answer)\n",
        "    возвращает словарь, содержащий ответ на вопрос (answer) и наиболее подходящий текст, откуда взят ответ (text)\n",
        "    \"\"\"\n",
        "    question_embeddings = encode_question(sem_tokenizer, question, sem_model, device)\n",
        "    text = search(question_embeddings, sentence_embeddings)\n",
        "    answer_dict = get_answer(qa_model, qa_tokenizer, question, text, device)\n",
        "    torch.cuda.empty_cache()\n",
        "    return answer_dict\n",
        "\n",
        "\n",
        "  # Определение параметров телеграм-бота (telebot)\n",
        "  your_bot = TOKEN\n",
        "  bot = telebot.TeleBot(your_bot)\n",
        "\n",
        "  # Готовые вопросы для телеграм-бота\n",
        "  questions = [\n",
        "    'Можешь рассказать о C++ (си-плюс-плюс)?',\n",
        "    'Что такое Dark Web (дарквеб, тёмная паутина)?',\n",
        "    'Что такое Midjourney?',\n",
        "    'Что такое Stable Diffusion?',\n",
        "    'Что такое Netfilter?',\n",
        "    'Что такое LLaMA?',\n",
        "    'Что такое уязвимость нулевого дня (также известная как 0-day)?',\n",
        "    'Хочу узнать про 5G',\n",
        "    'Что такое Битрикс24?',\n",
        "    'Что такое SOCKS?',\n",
        "    'Что такое DALL-E?',\n",
        "    'Что значит \"эмулятор\"?',\n",
        "    'Что такое троян?',\n",
        "    'Что такое интернет вещей?',\n",
        "    'Что такое Pretty Good Privacy?',\n",
        "    'Что такое макровирус?',\n",
        "    'Что такое лутбокс?',\n",
        "    'Какой хакер считается этичным?',\n",
        "    'Что такое honeypot?',\n",
        "    'Расскажи про первый компьютерный червь',\n",
        "    'Расскажи про UNIX',\n",
        "    'Что такое GitHub?',\n",
        "    'Что такое Linux?',\n",
        "    'Что такое ChatGPT?',\n",
        "    'Расскажи про проект Apache',\n",
        "    'Что такое резервная копия?',\n",
        "    'Что такое Clang?',\n",
        "    'Что такое биткойн?',\n",
        "    'Что такое Internet Standard?',\n",
        "    'Что значит Sensitive Information?'\n",
        "  ]\n",
        "\n",
        "  # Путь начала работы телеграм-бота\n",
        "  @bot.message_handler(commands=[\"start\"])\n",
        "  def start(message, res=False):\n",
        "    markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
        "    item1=types.KeyboardButton(\"Случайный вопрос\")\n",
        "    item2=types.KeyboardButton(\"Помощь\")\n",
        "    markup.row(item1, item2)\n",
        "    bot.send_message(message.chat.id, 'Здравствуйте! Я – Сиби (Cybersecurity Knowledge Bot). Я буду рад ответить на ваши вопросы по кибербезопасности. Пожалуйста, введите ваш вопрос:', reply_markup=markup)\n",
        "\n",
        "  # Путь телеграм-бота для получения и обработки вопроса пользователя к базе знаний\n",
        "  @bot.message_handler(content_types=[\"text\"])\n",
        "  def handle_text(message):\n",
        "\n",
        "    if message.text.strip() == 'Помощь':\n",
        "      answer = 'Введите интересующий вас вопрос по теме кибербезопасности или нажмите кнопку \"Случайный вопрос\". Я дам краткий ответ и подберу подходящую статью из базы знаний. Лучше всего я понимаю вопросы вида \"Что такое ChatGPT?\". Если ответ не подошел, попробуйте сформулировать вопрос по-другому.'\n",
        "      bot.send_message(message.chat.id, answer)\n",
        "\n",
        "    elif message.text.strip() == 'Случайный вопрос':\n",
        "      question = questions[random.randint(0, len(questions) - 1)]\n",
        "      answer_dict = process_question(question, sem_tokenizer, sem_model, device)\n",
        "      bot.send_message(message.chat.id, question)\n",
        "      bot.send_message(message.chat.id, \"Ответ: \" + answer_dict[\"answer\"])\n",
        "      bot.send_message(message.chat.id, \"Подробнее: \" + answer_dict[\"text\"])\n",
        "\n",
        "    else:\n",
        "      question = message.text.strip()\n",
        "      answer_dict = process_question(question, sem_tokenizer, sem_model, device)\n",
        "      bot.send_message(message.chat.id, \"Ответ: \" + answer_dict[\"answer\"])\n",
        "      bot.send_message(message.chat.id, \"Подробнее: \" + answer_dict[\"text\"])\n",
        "\n",
        "\n",
        "  # получение семантической модели и токенизатора\n",
        "  sem_model = get_semantic_model(device)\n",
        "  sem_tokenizer = get_semantic_tokenizer()\n",
        "\n",
        "  # получение qa-модели и токенизатора\n",
        "  qa_model = get_qa_model(device)\n",
        "  qa_tokenizer = get_qa_tokenizer()\n",
        "\n",
        "  # получение эмбеддингов и текстов базы знаний\n",
        "  sentence_embeddings = get_text_embeddings()\n",
        "  sentences = get_texts()\n",
        "  print(\"success\")\n",
        "\n",
        "  # активация телеграм-бота\n",
        "  bot.polling(none_stop=True, interval=0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "60SH57YTNwWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f5e9be-711b-41bc-b78b-bfcc10aaf146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytelegrambotapi in /usr/local/lib/python3.10/dist-packages (4.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytelegrambotapi) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (2024.6.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Mounted at /content/drive\n",
            "success\n"
          ]
        }
      ]
    }
  ]
}